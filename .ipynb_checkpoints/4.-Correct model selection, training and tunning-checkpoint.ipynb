{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12c5c12",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "Diferent algorithms will be run to find the one with the best metrics and results for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6f9733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97408076",
   "metadata": {},
   "source": [
    "# csv loading \n",
    "\n",
    "load train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd01c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.Path.cwd()\n",
    "\n",
    "#Loading train set\n",
    "path = pathlib.Path.cwd() / 'process sets' / 'xtrain_sel.csv'\n",
    "x_train = pd.read_csv(path, index_col= None)\n",
    "path = pathlib.Path.cwd() / 'process sets' / 'ytrain_sel.csv'\n",
    "y_train = pd.read_csv(path, index_col= None)\n",
    "\n",
    "\n",
    "#Loading test set\n",
    "path = pathlib.Path.cwd() / 'process sets' / 'xtest_sel.csv'\n",
    "x_test = pd.read_csv(path, index_col= None)\n",
    "path = pathlib.Path.cwd() / 'process sets' / 'ytest_sel.csv'\n",
    "y_test= pd.read_csv(path, index_col= None)\n",
    "\n",
    "\n",
    "\n",
    "#Preventive reset index and squeeze to avoid bugs\n",
    "y_train.reset_index(inplace=True)\n",
    "y_train.drop(\"index\", axis= 1, inplace=True)\n",
    "y_train = y_train.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "x = x_train.copy()\n",
    "y = y_train.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a37bec",
   "metadata": {},
   "source": [
    "# Defining cross validaton score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12a159d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crossvalidate and display score function based in mean squared error\n",
    "\n",
    "def cross_score(model,x,y):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    scores = cross_val_score(model, x, y,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    \n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30619cb",
   "metadata": {},
   "source": [
    "# Def model functions \n",
    "\n",
    "Since some models are stochastical and doesnt show the same result in every run, we run them n times and average the resulting evaluation metrics to choose the best\n",
    "\n",
    "Models:\n",
    "- Linear Regressor\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "- Support vector machine regressor\n",
    "- KG-Boost Regressor\n",
    "- K-n Neighbor regressor\n",
    "- Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca91811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of times to run each model\n",
    "nloop= 10\n",
    "\n",
    "\n",
    "#Defining Linear Regression function\n",
    "\n",
    "def lin_loop(x,y):\n",
    "    \n",
    "    #Rmse acumulation variable\n",
    "    rmseacum = 0\n",
    "    \n",
    "    #Model import\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    #Loop of model run\n",
    "    for i in range (nloop):\n",
    "        model_reg = LinearRegression()\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "# Defining Decision Tree Regression function\n",
    "\n",
    "def dtr_loop(x,y):\n",
    "    #Rmse acumulation variable\n",
    "    rmseacum = 0\n",
    "    \n",
    "    #Loop of model run\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    \n",
    "    for i in range (nloop):\n",
    "        model_reg = DecisionTreeRegressor()\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    #Scores average metrics\n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "#Defining Random Forest regression function\n",
    "\n",
    "def rfr_loop(x,y):\n",
    "    \n",
    "    rmseacum = 0\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "   \n",
    "    for i in range (nloop):\n",
    "        model_reg = RandomForestRegressor()\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    #Scores average metrics\n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Defining Support Vector Regression function\n",
    "\n",
    "def svr_loop(x,y):\n",
    "    #Rmse acumulation variable\n",
    "    rmseacum = 0\n",
    "    from sklearn.svm import SVR\n",
    "   \n",
    "\n",
    "    #Loop of model run\n",
    "    for i in range (nloop):\n",
    "        model_reg =  SVR(kernel=\"linear\")\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Scores average metrics\n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "#Defining XGBOOST Regression function\n",
    "def xg_loop(x,y):\n",
    "    \n",
    "    rmseacum = 0\n",
    "    import xgboost\n",
    "    print(xgboost.__version__)\n",
    "    from xgboost import XGBRegressor\n",
    "   \n",
    "    for i in range (nloop):\n",
    "        model_reg =  XGBRegressor()\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    \n",
    "    #Scores average metrics\n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "#Defining K-n Neighbors Regressor function\n",
    "\n",
    "\n",
    "def kn_loop(x,y):\n",
    "    \n",
    "    rmseacum = 0\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "   \n",
    "    for i in range (nloop):\n",
    "        model_reg =  KNeighborsRegressor()\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    #Scores average metrics\n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "#Defining Lasso Regressor function\n",
    "def lasso_loop(x,y):\n",
    "    \n",
    "    rmseacum = 0\n",
    "    from sklearn.linear_model import Lasso\n",
    "   \n",
    "    for i in range (nloop):\n",
    "        model_reg =  Lasso()\n",
    "        model_reg.fit(x, y)\n",
    "        model=  model_reg\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Scores acumulator using cross validation function\n",
    "        scores = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "        rmseacum= rmseacum + rmse_scores\n",
    "        print(\"it\", i)\n",
    "    \n",
    "    #Scores average metrics\n",
    "    rmse_scores = rmseacum/nloop\n",
    "    print(\"Model:\", str(model))\n",
    "    print(\"Scores:\",  rmse_scores)\n",
    "    print(\"MAE:\", round( rmse_scores.mean(),3))\n",
    "    print(\"RMEE:\",round(  rmse_scores.std(), 3))\n",
    "    print(\"MAE / data mean:\", round( (rmse_scores.mean()/ y.mean()),3))\n",
    "    print(\"RMEE / data std:\",round(  (rmse_scores.std()/ y.std()), 3))\n",
    "    \n",
    "    \n",
    "    return rmse_scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98facff8",
   "metadata": {},
   "source": [
    "# Models Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfdd419d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0\n",
      "it 1\n",
      "it 2\n",
      "it 3\n",
      "it 4\n",
      "it 5\n",
      "it 6\n",
      "it 7\n",
      "it 8\n",
      "it 9\n",
      "Model: LinearRegression()\n",
      "Scores: [58937.3798169  28709.72573867 31374.80687159 35240.08627964\n",
      " 40750.63842641 23427.99333511 27727.78355793 30789.63938308\n",
      " 46884.17401914 26799.92249634]\n",
      "MAE: 35064.215\n",
      "RMEE: 10352.741\n",
      "MAE / data mean: 0.194\n",
      "RMEE / data std: 0.13\n",
      "it 0\n",
      "it 1\n",
      "it 2\n",
      "it 3\n",
      "it 4\n",
      "it 5\n",
      "it 6\n",
      "it 7\n",
      "it 8\n",
      "it 9\n",
      "Model: DecisionTreeRegressor()\n",
      "Scores: [53016.80365556 41765.75365772 43728.985807   40190.6320584\n",
      " 38365.75029055 32130.80698462 36492.45215896 37118.78287098\n",
      " 47083.01263986 34323.73421758]\n",
      "MAE: 40421.671\n",
      "RMEE: 5935.546\n",
      "MAE / data mean: 0.223\n",
      "RMEE / data std: 0.075\n",
      "it 0\n",
      "it 1\n",
      "it 2\n",
      "it 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#LR RMSE\n",
    "lin_mod = lin_loop(x,y)\n",
    "#DTR RMSE\n",
    "dtr_mod = dtr_loop(x,y)\n",
    "#Random Forest RMSE\n",
    "rfr_mod= rfr_loop(x,y)\n",
    "#SVR RMSE\n",
    "svr_mod= svr_loop(x,y)\n",
    "#K-n RMSE\n",
    "kn_mod= kn_loop(x,y)\n",
    "#Lasso RMSE\n",
    "lasso_mod = lasso_loop(x,y)\n",
    "#Xg boost RMSE\n",
    "xg_mod = xg_loop(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53aa5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting best\n",
    "\n",
    "#model  results\n",
    "modelos =[lin_mod,dtr_mod, rfr_mod, svr_mod, kn_mod, lasso_mod, xg_mod]\n",
    "#model names\n",
    "modelos_nombres= [\"linear reg\",\"dt reg\", \"random forest reg\", \"SV Reg\", \"Kn Reg\", \"Lasso Reg\", \"XgBoost\"]\n",
    "\n",
    "#Initial proposed high Mae and RMSE to be replaced by a better one with models in the next cycle\n",
    "BestMAE = 10000000\n",
    "BestRMEE = 10000000\n",
    "\n",
    "\n",
    "#Finding best model with this cicle (normalized by expected mean and standar deviation)\n",
    "for n,i in enumerate (modelos):\n",
    "    #Normalizing results\n",
    "    MAE = (i.mean()/ y.mean())\n",
    "    RMEE =(i.std()/ y.std())\n",
    "    \n",
    "    #Saving top model bases in MAE and RMSE\n",
    "    if MAE < BestMAE:\n",
    "        BestMAE= MAE\n",
    "        ModelMAE= modelos_nombres[n]\n",
    "    if RMEE < BestRMEE:\n",
    "        BestRMEE= RMEE\n",
    "        ModelRMEE= modelos_nombres[n]\n",
    "        \n",
    "    \n",
    "    \n",
    "#printing\n",
    "print(\"Best MAE model: \", ModelMAE , \"MAE: \", BestMAE)\n",
    "print(\"Best RMSE model: \", ModelRMEE , \"RMSE: \", BestRMEE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f139d",
   "metadata": {},
   "source": [
    "# Choosed Model \n",
    "\n",
    "\n",
    "The choosed model to work with is Random Forest Regression, because it has low MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f24bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82d51e3",
   "metadata": {},
   "source": [
    "# Hyperparamater Tuning of Random Forest Regression\n",
    "\n",
    "- We can use grid search \n",
    "- We can use randomized search\n",
    "\n",
    "We will use randomized search approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3349012",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930267e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Params\n",
    "grid_search.best_params_\n",
    "\n",
    "\n",
    "#Best estimator\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search all possible combinations\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(\"sqt mean error: \", np.sqrt(-mean_score),  params)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7948f",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "#Parameter distibution limits\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "#running random search\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing all parameters\n",
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "\n",
    "#Showing the best estimator\n",
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing future importances for the best model\n",
    "feature_importances = rnd_search.best_estimator_.feature_importances_\n",
    "feature_importances\n",
    "\n",
    "attributes = list(x.columns)\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8ddfc",
   "metadata": {},
   "source": [
    "# Evaluate your model in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test set\n",
    "\n",
    "# dependent features (independent feature)\n",
    "xt = x_test.copy()\n",
    "\n",
    "# y feature (expected feature)\n",
    "yt = y_test.copy()\n",
    "\n",
    "#Preventive reset index and squeeze to avoid bugs\n",
    "yt.reset_index(inplace=True)\n",
    "yt.drop(\"index\", axis= 1, inplace=True)\n",
    "yt = yt.squeeze()\n",
    "\n",
    "\n",
    "#mean square error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "final_model = rnd_search.best_estimator_\n",
    "final_predictions = final_model.predict(xt)\n",
    "final_mse = mean_squared_error(yt, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"Mean square error total sum\", final_mse)\n",
    "print(\"Root mean square error total sum\", final_rmse)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56e465",
   "metadata": {},
   "source": [
    "# Dataframe with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a base dataframe\n",
    "df = pd.DataFrame(xt)\n",
    "\n",
    "#Adding predicted, expected, error abs and error % columns\n",
    "df[\"Predicted\"] = final_predictions\n",
    "df[\"Expected\"] = yt\n",
    "df[\"Error abs\"] =  (round(abs((df[\"Expected\"] - df[\"Predicted\"]) )))\n",
    "df[\"Error %\"] = (round(abs((df[\"Expected\"] - df[\"Predicted\"]) )/ df[\"Expected\"],3))*100\n",
    "\n",
    "#Printing maximum error, error mean and error std\n",
    "print(\"Error max  = \" ,(df[\"Error %\"].max()))\n",
    "print(\"Error mean  = \" ,(df[\"Error %\"].mean()))\n",
    "print(\"Error std  = \" ,(df[\"Error abs\"].std()))\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#Plot Predicted distribution\n",
    "plt.style.use('seaborn-dark')\n",
    "sns.jointplot(x=\"Expected\" , y =\"Predicted\", data = df, kind= \"reg\" , palette= \"viridis\", color=\"green\",  joint_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1}})\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f095f5d",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb11b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SAVE\n",
    "import joblib\n",
    "path = pathlib.Path.cwd() / 'process sets' / 'housing_model.sav'\n",
    "\n",
    "filename = path\n",
    "joblib.dump(final_model , filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO LOAD\n",
    "import joblib\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.predict(x)\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83310434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ceeae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
